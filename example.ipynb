{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5d3499-a6cb-470a-a1ce-c3063583d822",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1275cb4-7823-4136-b626-f5eb407d28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from evaluate_utils import get_val_data, get_val_pair, evaluate\n",
    "from get_model import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbd09c-5c35-40df-9bb5-168f0881d233",
   "metadata": {},
   "source": [
    "### Define necassary variables and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7510726c-20f5-41c1-a8b3-b11b6530a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_path = \"data/faces_emore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96909cb1-5414-4384-a94b-5c898a248ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets.repeat(2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data = self.inputs[idx]\n",
    "        target_data = self.targets[idx]\n",
    "\n",
    "        return input_data, target_data\n",
    "\n",
    "def crop_memmap(img_memmap, img_shape):\n",
    "    target_height = img_shape[0]\n",
    "    start_height = (112 - target_height) // 2\n",
    "    end_height = start_height + target_height\n",
    "\n",
    "    target_width = img_shape[1]\n",
    "    start_width = (112 - target_width) // 2\n",
    "    end_width = start_width + target_width\n",
    "    cropped_img_memmap = img_memmap[:, :, start_height:end_height, start_width:end_width]\n",
    "    print(cropped_img_memmap.shape)\n",
    "    return cropped_img_memmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b7e0d-5bdb-41b1-8d23-f9f87ef33709",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0195e-c868-4926-bfbe-49d516352a72",
   "metadata": {},
   "source": [
    "**Option #1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c22b06-fe62-41ab-b5bc-ed3d888bc3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation data memfile\n",
      "loading validation data memfile\n",
      "loading validation data memfile\n",
      "loading validation data memfile\n",
      "loading validation data memfile\n"
     ]
    }
   ],
   "source": [
    "val_data = get_val_data(\"data/faces_emore\")\n",
    "agedb_30, cfp_fp, lfw, agedb_30_issame, cfp_fp_issame, lfw_issame, cplfw, cplfw_issame, calfw, calfw_issame = val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ad639-af3c-497f-be53-e1f3f5fb1851",
   "metadata": {},
   "source": [
    "**Option #2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc44f304-be0b-4d7b-b32b-13a0eea7041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation data memfile\n",
      "loading validation data memfile\n",
      "loading validation data memfile\n",
      "loading validation data memfile\n",
      "loading validation data memfile\n"
     ]
    }
   ],
   "source": [
    "# inputs, targets\n",
    "# dataname_list = ['agedb_30', 'cfp_fp', 'lfw', 'cplfw', 'calfw']\n",
    "agedb_30, agedb_30_issame = get_val_pair(data_path, 'agedb_30')\n",
    "cfp_fp, cfp_fp_issame = get_val_pair(data_path, 'cfp_fp')\n",
    "lfw, lfw_issame = get_val_pair(data_path, 'lfw')\n",
    "cplfw, cplfw_issame = get_val_pair(data_path, 'cplfw')\n",
    "calfw, calfw_issame = get_val_pair(data_path, 'calfw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6f8e7-2804-44ac-bc8a-fd1f72cd5cb6",
   "metadata": {},
   "source": [
    "**Build dataset**\n",
    "\n",
    "backbone architecture 찾을수 있으면 계속 추가 가능함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0fc78b-3dc5-4cd7-83f5-981f5305436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing checkpoint: ckpts/model_ir_se50.pth\n",
      "Load existing checkpoint: ckpts/cosface.pth\n"
     ]
    }
   ],
   "source": [
    "model, img_shape = get_model(\"AdaFace\")\n",
    "model, img_shape = get_model(\"ArcFace\")\n",
    "model, img_shape = get_model(\"CosFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5fd6e2-7650-43ba-a589-d0e89f7c745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 3, 112, 96)\n",
      "(14000, 3, 112, 96)\n",
      "(12000, 3, 112, 96)\n",
      "(12000, 3, 112, 96)\n",
      "(12000, 3, 112, 96)\n"
     ]
    }
   ],
   "source": [
    "if img_shape != (112, 112):\n",
    "    agedb_30 = crop_memmap(agedb_30, img_shape)\n",
    "    cfp_fp = crop_memmap(cfp_fp, img_shape)\n",
    "    lfw = crop_memmap(lfw, img_shape)\n",
    "    cplfw = crop_memmap(cplfw, img_shape)\n",
    "    calfw = crop_memmap(calfw, img_shape)\n",
    "    \n",
    "dataset_agedb_30 = FRDataset(agedb_30, agedb_30_issame)\n",
    "dataset_cfp_fp = FRDataset(cfp_fp, cfp_fp_issame)\n",
    "dataset_lfw = FRDataset(lfw, lfw_issame)\n",
    "dataset_cplfw = FRDataset(cplfw, cplfw_issame)\n",
    "dataset_calfw = FRDataset(calfw, calfw_issame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62031ead-1499-4f24-b070-843053607a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_dataloader = DataLoader(dataset_agedb_30,\n",
    "                             batch_size=128,\n",
    "                             num_workers=8,\n",
    "                             shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48560f9e-c0b6-42d1-8b79-4fc7468509a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter [10/94] - TAR@FAR=0.01%: 0.8162\n",
      "Iter [20/94] - TAR@FAR=0.01%: 0.8840\n",
      "Iter [30/94] - TAR@FAR=0.01%: 0.8935\n",
      "Iter [40/94] - TAR@FAR=0.01%: 0.8952\n",
      "Iter [50/94] - TAR@FAR=0.01%: 0.9082\n",
      "Iter [60/94] - TAR@FAR=0.01%: 0.9101\n",
      "Iter [70/94] - TAR@FAR=0.01%: 0.9169\n",
      "Iter [80/94] - TAR@FAR=0.01%: 0.9195\n",
      "Iter [90/94] - TAR@FAR=0.01%: 0.9222\n",
      "Result TAR@FAR=0.01% - 0.9353343465045592\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for idx, (inputs, targets) in enumerate(test_dataloader):\n",
    "    features = model.forward(inputs.to(device), False)\n",
    "    tpr, fpr, accuracy, best_thresholds = evaluate(features.detach().cpu().numpy(), targets[0::2])\n",
    "    if idx > 0 and (idx) % 10 == 0:\n",
    "        print(f\"Iter [{idx}/{len(test_dataloader)}] - TAR@FAR=0.01%: {acc/(idx+1):.4f}\")\n",
    "    # acc, best_threshold = accuracy.mean(), best_thresholds.mean()\n",
    "    acc += accuracy.mean()\n",
    "print(f\"Result TAR@FAR=0.01% - {acc/(idx+1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
